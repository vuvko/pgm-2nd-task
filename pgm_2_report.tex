\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage[colorlinks,urlcolor=blue]{hyperref}
\usepackage[space]{grffile}
\usepackage{caption, subcaption,amsmath,amssymb,graphicx,multicol,epstopdf}

\begin{document}

\begin{titlepage}
\begin{center}
  Московский Государственный университет имени М. В. Ломоносова\\
  Факультет Вычислительной Математики и Кибернетики\\
  Кафедра Математических Методов Прогнозирования\\[30mm]

  \Large\bfseries
    Задание по графическим моделям №2\\[5mm]
    <<Низкоплотностное кодирование>>
  \\[40mm]
\end{center}
\begin{flushright}
  Шадриков Андрей

  группа 417
\end{flushright}
\center\vspace{\fill} 
  Москва, 2014
\end{titlepage}

\tableofcontents
\newpage

\section{Постановка задачи}

Рассматривается задача помехоустойчивого блочного кодирования.
Имеется сообщение длины $k$, которое мы хотим закодировать сообщением длины $n$ для передачи по бинарному симметричному каналу, где вероятность битовой ошибки --- $q$.

\[
  u \in \{0, 1\}^k \xrightarrow{coding} v \in \{0, 1\}^n \xrightarrow[(noise)]{transfer} w \in \{0, 1\}^n \xrightarrow{unnoise} \hat{v} \in \{0, 1\}^n \xrightarrow{decoding} \hat{u} \in \{0, 1\}^n
\]

Можно задавать код его проверочной бинарной матрицей $H \in \{0,\,1\}^{(n - k) n} : H u = 0$, по которой можно построить порождающую матрицу $G : G u = v$.
Особенность низкоплотностных кодов заключается в сильно разреженной матрице $H$, т.е. в ней малое количество единиц.

Пусть имеется полученное сообщение $w$.
Тогда синдромом назовём $s = H w$.
Теперь если представить $w$ в виде $v + e$, где $e$ --- вектор ошибок, то получаем: $s = H w = H (v + e) = H v + H e = H e$.
Основная задача декодирования --- восстановление вектора ошибок $e$, потому что по нему уже легко восстановить исходное сообщение $\hat{v} = w + e$.

Восстанавливать вектор ошибок будем используя аппарат графических моделей и алгоритм передачи сообщений Loopy Belief Propogation.
Более подробно про постановку задачи и вывод необходимых формул можно найти в \cite{task}.

\section{Эксперименты}

\subsection{Расписание и коэффициент демпфирования}

Поскольку гарантий на сходимость метода у нас нет, то приходится использовать некоторые ухищрения.
В частности для решения задачи декодирования были применены два расписания: последовательное и параллельное, а также различные коэффициенты демпфирования.

При сравнении работы алгоритма были использованы следующие параметры: $n = 256, k = 32, q = 0.1$, а результаты усреднялись по 5-ти запускам.
Алгоритмы сравнивались по скорости работы и доли стабилизировшихся beliefs.
Результаты приведены в таблице \ref{tbl:time} и на графиках \ref{fig:par}, \ref{fig:seq}

% сюда вставить графики

Из графиков видно, что лучше работает последовательное расписание, а также чем больше $\lambda$, тем лучше, до тех пор, пока $\lambda < 1$.

\subsection{Оценка блочной и битовой ошибки}



\subsection{Сравнение с кодами БЧХ}

\begin{thebibliography}{0}

\bibitem{task}
  \href{http://www.machinelearning.ru/wiki/index.php?title=%D0%93%D1%80%D0%B0%D1%84%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B5_%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8_%28%D0%BA%D1%83%D1%80%D1%81_%D0%BB%D0%B5%D0%BA%D1%86%D0%B8%D0%B9%29/2014/%D0%97%D0%B0%D0%B4%D0%B0%D0%BD%D0%B8%D0%B5_2}{Полный текст задания}

\end{thebibliography}

\end{document}